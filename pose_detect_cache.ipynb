{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pylab import array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization with body_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.dnn.Net 00000188E3B132B0>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# COCO\n",
    "protoFile = \"models/pose/coco/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"models/pose/coco/pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "# MPI\n",
    "protoFile = \"models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"models/pose/mpi/pose_iter_160000.caffemodel\"\n",
    "nPoints = 15\n",
    "POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\"\"\"\n",
    "\n",
    "protoFile = \"models/pose/body_25/pose_deploy.prototxt\"\n",
    "weightsFile = \"models/pose/body_25/pose_iter_584000.caffemodel\"\n",
    "nPoints = 25\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 00000188E4345810>\n"
     ]
    }
   ],
   "source": [
    "# 1 is USB webcam\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "print(cap)\n",
    "\n",
    "while(True):\n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow('frame', frame)  # Display the resulting frame\n",
    "    cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)  # Make it appear on top\n",
    "   \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️⚠️⚠️ Reading in the frames ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 51.85546875\n"
     ]
    }
   ],
   "source": [
    "# Give some time for setup\n",
    "time.sleep(4)\n",
    "\n",
    "FRAMES_READ = 60*5\n",
    "FRAMES_SKIP = 5\n",
    "frames = []\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)  # Apparently CAP_DSHOW makes it faster\n",
    "\n",
    "for i in range(FRAMES_READ):\n",
    "    # Not adding the first iteration of frames because camrea adjusts to lighting\n",
    "    if i % FRAMES_SKIP == 0 and i != 0:\n",
    "        frames.append(frame)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Get number of frames and size of `FRAMES` array in MB\n",
    "print(len(frames), array(frames).nbytes/(1024*1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Cached Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1\n",
      "Frame 2\n",
      "Frame 3\n",
      "Frame 4\n",
      "Frame 5\n",
      "Frame 6\n",
      "Frame 7\n",
      "Frame 8\n",
      "Frame 9\n",
      "Frame 10\n",
      "Frame 11\n",
      "Frame 12\n",
      "Frame 13\n",
      "Frame 14\n",
      "Frame 15\n",
      "Frame 16\n",
      "Frame 17\n",
      "Frame 18\n",
      "Frame 19\n",
      "Frame 20\n",
      "Frame 21\n",
      "Frame 22\n",
      "Frame 23\n",
      "Frame 24\n",
      "Frame 25\n",
      "Frame 26\n",
      "Frame 27\n",
      "Frame 28\n",
      "Frame 29\n",
      "Frame 30\n",
      "Frame 31\n",
      "Frame 32\n",
      "Frame 33\n",
      "Frame 34\n",
      "Frame 35\n",
      "Frame 36\n",
      "Frame 37\n",
      "Frame 38\n",
      "Frame 39\n",
      "Frame 40\n",
      "Frame 41\n",
      "Frame 42\n",
      "Frame 43\n",
      "Frame 44\n",
      "Frame 45\n",
      "Frame 46\n",
      "Frame 47\n",
      "Frame 48\n",
      "Frame 49\n",
      "Frame 50\n",
      "Frame 51\n",
      "Frame 52\n",
      "Frame 53\n",
      "Frame 54\n",
      "Frame 55\n",
      "Frame 56\n",
      "Frame 57\n",
      "Frame 58\n",
      "Frame 59\n"
     ]
    }
   ],
   "source": [
    "LOOP = 1\n",
    "\n",
    "for _ in range(LOOP):\n",
    "    for i, frame in enumerate(frames, start=1):\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)  # Doesn't play automatically, hit any key to move to next frame\n",
    "        cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "        print(f\"Frame {i}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 1\n",
      "Processed frame 2\n",
      "Processed frame 3\n",
      "Processed frame 4\n",
      "Processed frame 5\n",
      "Processed frame 6\n",
      "Processed frame 7\n",
      "Processed frame 8\n",
      "Processed frame 9\n",
      "Processed frame 10\n",
      "Processed frame 11\n",
      "Processed frame 12\n",
      "Processed frame 13\n",
      "Processed frame 14\n",
      "Processed frame 15\n",
      "Processed frame 16\n",
      "Processed frame 17\n",
      "Processed frame 18\n",
      "Processed frame 19\n",
      "Processed frame 20\n",
      "Processed frame 21\n",
      "Processed frame 22\n",
      "Processed frame 23\n",
      "Processed frame 24\n",
      "Processed frame 25\n",
      "Processed frame 26\n",
      "Processed frame 27\n",
      "Processed frame 28\n",
      "Processed frame 29\n",
      "Processed frame 30\n",
      "Processed frame 31\n",
      "Processed frame 32\n",
      "Processed frame 33\n",
      "Processed frame 34\n",
      "Processed frame 35\n",
      "Processed frame 36\n",
      "Processed frame 37\n",
      "Processed frame 38\n",
      "Processed frame 39\n",
      "Processed frame 40\n",
      "Processed frame 41\n",
      "Processed frame 42\n",
      "Processed frame 43\n",
      "Processed frame 44\n",
      "Processed frame 45\n",
      "Processed frame 46\n",
      "Processed frame 47\n",
      "Processed frame 48\n",
      "Processed frame 49\n",
      "Processed frame 50\n",
      "Processed frame 51\n",
      "Processed frame 52\n",
      "Processed frame 53\n",
      "Processed frame 54\n",
      "Processed frame 55\n",
      "Processed frame 56\n",
      "Processed frame 57\n",
      "Processed frame 58\n",
      "Processed frame 59\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# The actual body parts\n",
    "body_parts_dict = {\n",
    "    0: \"Nose\",\n",
    "    1: \"Neck\",\n",
    "    2: \"RShoulder\",\n",
    "    3: \"RElbow\",\n",
    "    4: \"RWrist\",\n",
    "    5: \"LShoulder\",\n",
    "    6: \"LElbow\",\n",
    "    7: \"LWrist\",\n",
    "    8: \"MidHip\",\n",
    "    9: \"RHip\",\n",
    "    10: \"RKnee\",\n",
    "    11: \"RAnkle\",\n",
    "    12: \"LHip\",\n",
    "    13: \"LKnee\",\n",
    "    14: \"LAnkle\",\n",
    "    15: \"REye\",\n",
    "    16: \"LEye\",\n",
    "    17: \"REar\",\n",
    "    18: \"LEar\",\n",
    "    19: \"LBigToe\",\n",
    "    20: \"LSmallToe\",\n",
    "    21: \"LHeel\",\n",
    "    22: \"RBigToe\",\n",
    "    23: \"RSmallToe\",\n",
    "    24: \"RHeel\",\n",
    "    25: \"Background\"\n",
    "}\n",
    "\n",
    "# Some are excluded\n",
    "head_and_neak = {0, 1}  # 0.07\n",
    "trunk = {8, 9, 12}  # 0.43\n",
    "upper_limbs = {2, 3, 4, 5, 6, 7}  # 0.13\n",
    "lower_limbs = {10, 11, 13, 14}  # 0.37\n",
    "union = head_and_neak | trunk | upper_limbs | lower_limbs\n",
    "\n",
    "loop = []\n",
    "center_of_grav_loc = []\n",
    "\n",
    "for j, frame in enumerate(frames, start=1):\n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    threshold = 0.1\n",
    "\n",
    "    inWidth = 640//3\n",
    "    inHeight = 480//3\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # Bottleneck\n",
    "    net.setInput(inpBlob)\n",
    "    output = net.forward()\n",
    "    \n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "\n",
    "    x_sum = 0\n",
    "    y_sum = 0\n",
    "\n",
    "    for i in range(nPoints):\n",
    "        # If the point is excluded from the minimum points required\n",
    "        if i not in union:\n",
    "            continue\n",
    "\n",
    "        # Weighting of an individual body part to be assigned\n",
    "        weight = None\n",
    "\n",
    "        # Identify the set its in\n",
    "        if i in head_and_neak:\n",
    "            weight = 0.07/len(head_and_neak)\n",
    "        elif i in trunk:\n",
    "            weight = 0.43/len(trunk)\n",
    "        elif i in upper_limbs:\n",
    "            weight = 0.13/len(upper_limbs)\n",
    "        elif i in lower_limbs:\n",
    "            weight = 0.37/len(lower_limbs)\n",
    "\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        # Weighted average\n",
    "        x_sum += x*weight\n",
    "        y_sum += y*weight\n",
    "\n",
    "        if prob > threshold or 1:\n",
    "            # Body part location and text\n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 4, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, f\"{i}: {body_parts_dict[i]}\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "        else :\n",
    "            points.append(None)\n",
    "    \n",
    "    # Draw center of gravity as a green circle and add it to array for tracking\n",
    "    cv2.circle(frameCopy, (int(x_sum), int(y_sum)), 10, (0, 255, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "    center_of_grav_loc.append((int(x_sum), int(y_sum)))\n",
    "\n",
    "    \"\"\"\n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "    \"\"\"\n",
    "\n",
    "    # Adding annotated frame for COG analysis\n",
    "    loop.append(frameCopy)\n",
    "\n",
    "    print(f\"Processed frame {j}\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the Tracked COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0\n",
      "Frame 1\n",
      "Frame 2\n",
      "Frame 3\n",
      "Frame 4\n",
      "Frame 5\n",
      "Frame 6\n",
      "Frame 7\n",
      "Frame 8\n",
      "Frame 9\n",
      "Frame 10\n",
      "Frame 11\n",
      "Frame 12\n",
      "Frame 13\n",
      "Frame 14\n",
      "Frame 15\n",
      "Frame 16\n",
      "Frame 17\n",
      "Frame 18\n",
      "Frame 19\n",
      "Frame 20\n",
      "Frame 21\n",
      "Frame 22\n",
      "Frame 23\n",
      "Frame 24\n",
      "Frame 25\n",
      "Frame 26\n",
      "Frame 27\n",
      "Frame 28\n",
      "Frame 29\n",
      "Frame 30\n",
      "Frame 31\n",
      "Frame 32\n",
      "Frame 33\n",
      "Frame 34\n",
      "Frame 35\n",
      "Frame 36\n",
      "Frame 37\n",
      "Frame 38\n",
      "Frame 39\n",
      "Frame 40\n",
      "Frame 41\n",
      "Frame 42\n",
      "Frame 43\n",
      "Frame 44\n",
      "Frame 45\n",
      "Frame 46\n",
      "Frame 47\n",
      "Frame 48\n",
      "Frame 49\n",
      "Frame 50\n",
      "Frame 51\n",
      "Frame 52\n",
      "Frame 53\n",
      "Frame 54\n",
      "Frame 55\n",
      "Frame 56\n",
      "Frame 57\n",
      "Frame 58\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, frame \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loop):\n\u001b[0;32m      5\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m, frame)\n\u001b[1;32m----> 6\u001b[0m     cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m     cv2\u001b[39m.\u001b[39msetWindowProperty(\u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m, cv2\u001b[39m.\u001b[39mWND_PROP_TOPMOST, \u001b[39m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFrame \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOOP = 10\n",
    "\n",
    "for _ in range(LOOP):\n",
    "    for i, frame in enumerate(loop):\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "  \n",
    "        print(f\"Frame {i}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COG Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "\n",
    "for i, j in zip(center_of_grav_loc[:-1], center_of_grav_loc[1:]):\n",
    "    dist = math.dist(i, j)\n",
    "    tot += dist\n",
    "    print(f\"{i} -> {j}: {dist} pixels\")\n",
    "\n",
    "print(tot, \"pixels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centtr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
