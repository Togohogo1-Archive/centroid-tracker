{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pylab import array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization with body_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# COCO\n",
    "protoFile = \"models/pose/coco/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"models/pose/coco/pose_iter_440000.caffemodel\"\n",
    "nPoints = 18\n",
    "POSE_PAIRS = [[1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "# MPI\n",
    "protoFile = \"models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"models/pose/mpi/pose_iter_160000.caffemodel\"\n",
    "nPoints = 15\n",
    "POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "\"\"\"\n",
    "\n",
    "protoFile = \"models/pose/body_25/pose_deploy.prototxt\"\n",
    "weightsFile = \"models/pose/body_25/pose_iter_584000.caffemodel\"\n",
    "nPoints = 25\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "print(net)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is USB webcam\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "print(cap)\n",
    "\n",
    "while(True):\n",
    "    # Capture the video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow('frame', frame)  # Display the resulting frame\n",
    "    cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)  # Make it appear on top\n",
    "   \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️⚠️⚠️ Reading in the Frames ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give some time for setup\n",
    "time.sleep(2)\n",
    "\n",
    "# Image saving stuff\n",
    "stamp = str(datetime.utcnow()).replace(\":\", \"_\").replace(\" \", \",\")\n",
    "Path(f\"./saved_generated/in_{stamp}\").mkdir(parents=True, exist_ok=False)\n",
    "SAVE_IMAGE = True\n",
    "\n",
    "# Frame reading stuff\n",
    "FRAMES_READ = 20\n",
    "FRAMES_SKIP = 5\n",
    "frames = []\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Apparently CAP_DSHOW makes it faster\n",
    "\n",
    "for i in range(FRAMES_READ):\n",
    "    # Not adding the first iteration of frames because camrea adjusts to lighting\n",
    "    if i % FRAMES_SKIP == 0 and i != 0:\n",
    "        frames.append(frame)\n",
    "        \n",
    "        if SAVE_IMAGE:\n",
    "            print(cv2.imwrite(f\"./saved_generated/in_{stamp}/frame{i}.jpg\", frame))\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Get number of frames and size of `FRAMES` array in MB\n",
    "print(len(frames), array(frames).nbytes/(1024*1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Cached Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP = 10\n",
    "\n",
    "for _ in range(LOOP):\n",
    "    for i, frame in enumerate(frames, start=1):\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)  # Doesn't play automatically, hit any key to move to next frame\n",
    "        cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "\n",
    "        print(f\"Frame {i}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual body parts\n",
    "body_parts_dict = {\n",
    "    0: \"Nose\",\n",
    "    1: \"Neck\",\n",
    "    2: \"RShoulder\",\n",
    "    3: \"RElbow\",\n",
    "    4: \"RWrist\",\n",
    "    5: \"LShoulder\",\n",
    "    6: \"LElbow\",\n",
    "    7: \"LWrist\",\n",
    "    8: \"MidHip\",\n",
    "    9: \"RHip\",\n",
    "    10: \"RKnee\",\n",
    "    11: \"RAnkle\",\n",
    "    12: \"LHip\",\n",
    "    13: \"LKnee\",\n",
    "    14: \"LAnkle\",\n",
    "    15: \"REye\",\n",
    "    16: \"LEye\",\n",
    "    17: \"REar\",\n",
    "    18: \"LEar\",\n",
    "    19: \"LBigToe\",\n",
    "    20: \"LSmallToe\",\n",
    "    21: \"LHeel\",\n",
    "    22: \"RBigToe\",\n",
    "    23: \"RSmallToe\",\n",
    "    24: \"RHeel\",\n",
    "    25: \"Background\"\n",
    "}\n",
    "\n",
    "# Some are excluded\n",
    "head_and_neak = {0, 1}  # 0.07\n",
    "trunk = {8, 9, 12}  # 0.43\n",
    "upper_limbs = {2, 3, 4, 5, 6, 7}  # 0.13\n",
    "lower_limbs = {10, 11, 13, 14}  # 0.37\n",
    "union = head_and_neak | trunk | upper_limbs | lower_limbs\n",
    "\n",
    "loop = []\n",
    "center_of_grav_loc = []\n",
    "\n",
    "# Image saving stuff\n",
    "stamp = str(datetime.utcnow()).replace(\":\", \"_\").replace(\" \", \",\")\n",
    "Path(f\"./saved_generated/out_{stamp}\").mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "for j, frame in enumerate(frames, start=1):\n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    threshold = 0.1\n",
    "\n",
    "    inWidth = 640\n",
    "    inHeight = 480\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # Bottleneck\n",
    "    net.setInput(inpBlob)\n",
    "    output = net.forward()\n",
    "    \n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "\n",
    "    x_sum = 0\n",
    "    y_sum = 0\n",
    "\n",
    "    for i in range(nPoints):\n",
    "        # If the point is excluded from the minimum points required\n",
    "        if i not in union:\n",
    "            continue\n",
    "\n",
    "        # Weighting of an individual body part to be assigned\n",
    "        weight = None\n",
    "\n",
    "        # Identify the set its in\n",
    "        if i in head_and_neak:\n",
    "            weight = 0.07/len(head_and_neak)\n",
    "        elif i in trunk:\n",
    "            weight = 0.43/len(trunk)\n",
    "        elif i in upper_limbs:\n",
    "            weight = 0.13/len(upper_limbs)\n",
    "        elif i in lower_limbs:\n",
    "            weight = 0.37/len(lower_limbs)\n",
    "\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        # Weighted average\n",
    "        x_sum += x*weight\n",
    "        y_sum += y*weight\n",
    "\n",
    "        if prob > threshold or 1:\n",
    "            # Body part location and text\n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 4, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, f\"{i}: {body_parts_dict[i]}\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "        else :\n",
    "            points.append(None)\n",
    "    \n",
    "    # Draw center of gravity as a green circle and add it to array for tracking\n",
    "    cv2.circle(frameCopy, (int(x_sum), int(y_sum)), 10, (0, 255, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "    center_of_grav_loc.append((int(x_sum), int(y_sum)))\n",
    "\n",
    "    \"\"\"\n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "            cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "    \"\"\"\n",
    "\n",
    "    # Adding annotated frame for COG analysis\n",
    "    loop.append(frameCopy)\n",
    "\n",
    "    if SAVE_IMAGE:\n",
    "        print(cv2.imwrite(f\"./saved_generated/out_{stamp}/frame{j}.jpg\", frameCopy))\n",
    "\n",
    "    print(f\"Processed frame {j}\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the Tracked COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOP = 10\n",
    "\n",
    "for _ in range(LOOP):\n",
    "    for i, frame in enumerate(loop):\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "  \n",
    "        print(f\"Frame {i}\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COG Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "\n",
    "for i, j in zip(center_of_grav_loc[:-1], center_of_grav_loc[1:]):\n",
    "    dist = math.dist(i, j)\n",
    "    tot += dist\n",
    "    print(f\"{i} -> {j}: {dist} pixels\")\n",
    "\n",
    "print(tot, \"pixels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centtr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
