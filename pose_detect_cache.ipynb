{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pylab import array\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Initialization\n",
    "\n",
    "COCO Output Format Nose – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4, Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8, Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12, LAnkle – 13, Right Eye – 14, Left Eye – 15, Right Ear – 16, Left Ear – 17, Background – 18\n",
    "\n",
    "MPII Output Format Head – 0, Neck – 1, Right Shoulder – 2, Right Elbow – 3, Right Wrist – 4, Left Shoulder – 5, Left Elbow – 6, Left Wrist – 7, Right Hip – 8, Right Knee – 9, Right Ankle – 10, Left Hip – 11, Left Knee – 12, Left Ankle – 13, Chest – 14, Background – 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"MPI\"\n",
    "\n",
    "if MODE is \"COCO\":\n",
    "    protoFile = \"models/pose/coco/pose_deploy_linevec.prototxt\"\n",
    "    weightsFile = \"models/pose/coco/pose_iter_440000.caffemodel\"\n",
    "    nPoints = 18\n",
    "    POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "elif MODE is \"MPI\" :\n",
    "    protoFile = \"models/pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "    weightsFile = \"models/pose/mpi/pose_iter_160000.caffemodel\"\n",
    "    nPoints = 15\n",
    "    POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "    body_parts = {\n",
    "        0: \"Head\",\n",
    "        1: \"Neck\",\n",
    "        2: \"Right Shoulder\",\n",
    "        3: \"Right Elbow\",\n",
    "        4: \"Right Wrist\",\n",
    "        5: \"Left Shoulder\",\n",
    "        6: \"Left Elbow\",\n",
    "        7: \"Left Wrist\",\n",
    "        8: \"Right Hip\",\n",
    "        9: \"Right Knee\",\n",
    "        10: \"Right Ankle\",\n",
    "        11: \"Left Hip\",\n",
    "        12: \"Left Knee\",\n",
    "        13: \"Left Ankle\",\n",
    "        14: \"Chest\",\n",
    "        15: \"Background\"\n",
    "    }\n",
    "    weight_distrib = {\n",
    "        0: 0.07/2,\n",
    "        1: 0.07/2,\n",
    "        2: 0.13/6,\n",
    "        3: 0.13/6,\n",
    "        4: 0.13/6,\n",
    "        5: 0.13/6,\n",
    "        6: 0.13/6,\n",
    "        7: 0.13/6,\n",
    "        8: 0.43/3,\n",
    "        9: 0.37/4,\n",
    "        10: 0.37/4,\n",
    "        11: 0.43/3,\n",
    "        12: 0.37/4,\n",
    "        13: 0.37/4,\n",
    "        14: 0.43/3,\n",
    "        15: \"Background\"\n",
    "    }\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "print(\"Using CPU device\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing camera\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "\n",
    "# cap.set(cv2.CAP_PROP_EXPOSURE, -8.0)\n",
    "print(cap)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 52.734375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(4)\n",
    "# Initial video reading\n",
    "FRAMES_READ = 60  # Assume 30 fps\n",
    "FRAMES = []\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)  # Apparently dshow makes it faster\n",
    "for i in range(FRAMES_READ):\n",
    "    ret, frame = cap.read()\n",
    "    FRAMES.append(frame)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n",
    "print(len(FRAMES), array(FRAMES).nbytes/(1024*1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "# for j in loop[:5]:\n",
    "    # print(j)\n",
    "# print(loop)\n",
    "# import time\n",
    "for _ in range(1):\n",
    "    for frame in FRAMES:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)\n",
    "        # cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "        print(\"bruh\")\n",
    "        # time.sleep(2)\n",
    "        # cv2.imshow(\"frame\", loop)\n",
    "        # print(\"bruh2\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "processing...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "loop = []\n",
    "center_of_grav_loc = []\n",
    "\n",
    "for frame in FRAMES:\n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    threshold = 0.1\n",
    "\n",
    "    inWidth = 250\n",
    "    inHeight = 250\n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                            (0, 0, 0), swapRB=False, crop=False)\n",
    "    net.setInput(inpBlob)\n",
    "    # Bottleneck\n",
    "\n",
    "    output = net.forward()\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "\n",
    "    # Empty list to store the detected keypoints\n",
    "    points = []\n",
    "\n",
    "    x_sum = 0\n",
    "    y_sum = 0\n",
    "\n",
    "    for i in range(nPoints):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        x_sum += x*weight_distrib[i]\n",
    "        y_sum += y*weight_distrib[i]\n",
    "\n",
    "        if prob > threshold or 1:\n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 4, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, f\"{i}: {body_parts[i]}\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "    \n",
    "    cv2.circle(frameCopy, (int(x_sum), int(y_sum)), 10, (0, 255, 0), thickness=-1, lineType=cv2.FILLED)\n",
    "    center_of_grav_loc.append((int(x_sum), int(y_sum)))\n",
    "\n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        # if points[partA] and points[partB]:\n",
    "        #     cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "        #     cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "    loop.append(frameCopy)\n",
    "    # cv2.imshow('Output-Keypoints', frameCopy)\n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    print(\"processing...\")\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n",
      "bruh\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "# for j in loop[:5]:\n",
    "    # print(j)\n",
    "# print(loop)\n",
    "# import time\n",
    "for _ in range(1):\n",
    "    for frame in loop:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.waitKey(0)\n",
    "        # cv2.setWindowProperty(\"frame\", cv2.WND_PROP_TOPMOST, 1)\n",
    "        print(\"bruh\")\n",
    "        # time.sleep(2)\n",
    "        # cv2.imshow(\"frame\", loop)\n",
    "        # print(\"bruh2\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COG Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 235) -> (279, 230): 9.433981132056603 pixels\n",
      "(279, 230) -> (276, 230): 3.0 pixels\n",
      "(276, 230) -> (281, 230): 5.0 pixels\n",
      "(281, 230) -> (281, 230): 0.0 pixels\n",
      "(281, 230) -> (281, 230): 0.0 pixels\n",
      "(281, 230) -> (281, 230): 0.0 pixels\n",
      "(281, 230) -> (279, 232): 2.8284271247461903 pixels\n",
      "(279, 232) -> (280, 230): 2.23606797749979 pixels\n",
      "(280, 230) -> (279, 232): 2.23606797749979 pixels\n",
      "(279, 232) -> (276, 232): 3.0 pixels\n",
      "(276, 232) -> (274, 232): 2.0 pixels\n",
      "(274, 232) -> (276, 232): 2.0 pixels\n",
      "(276, 232) -> (274, 232): 2.0 pixels\n",
      "(274, 232) -> (276, 232): 2.0 pixels\n",
      "(276, 232) -> (281, 232): 5.0 pixels\n",
      "(281, 232) -> (281, 230): 2.0 pixels\n",
      "(281, 230) -> (281, 230): 0.0 pixels\n",
      "(281, 230) -> (279, 230): 2.0 pixels\n",
      "(279, 230) -> (277, 230): 2.0 pixels\n",
      "(277, 230) -> (283, 230): 6.0 pixels\n",
      "(283, 230) -> (281, 230): 2.0 pixels\n",
      "(281, 230) -> (284, 230): 3.0 pixels\n",
      "(284, 230) -> (284, 229): 1.0 pixels\n",
      "(284, 229) -> (281, 228): 3.1622776601683795 pixels\n",
      "(281, 228) -> (283, 230): 2.8284271247461903 pixels\n",
      "(283, 230) -> (285, 231): 2.23606797749979 pixels\n",
      "(285, 231) -> (288, 226): 5.830951894845301 pixels\n",
      "(288, 226) -> (288, 224): 2.0 pixels\n",
      "(288, 224) -> (291, 229): 5.830951894845301 pixels\n",
      "(291, 229) -> (289, 228): 2.23606797749979 pixels\n",
      "(289, 228) -> (290, 230): 2.23606797749979 pixels\n",
      "(290, 230) -> (295, 233): 5.830951894845301 pixels\n",
      "(295, 233) -> (300, 231): 5.385164807134504 pixels\n",
      "(300, 231) -> (301, 233): 2.23606797749979 pixels\n",
      "(301, 233) -> (300, 233): 1.0 pixels\n",
      "(300, 233) -> (302, 236): 3.605551275463989 pixels\n",
      "(302, 236) -> (301, 234): 2.23606797749979 pixels\n",
      "(301, 234) -> (299, 240): 6.324555320336759 pixels\n",
      "(299, 240) -> (305, 242): 6.324555320336759 pixels\n",
      "(305, 242) -> (305, 246): 4.0 pixels\n",
      "(305, 246) -> (308, 248): 3.605551275463989 pixels\n",
      "(308, 248) -> (310, 249): 2.23606797749979 pixels\n",
      "(310, 249) -> (309, 249): 1.0 pixels\n",
      "(309, 249) -> (312, 256): 7.615773105863909 pixels\n",
      "(312, 256) -> (311, 255): 1.4142135623730951 pixels\n",
      "(311, 255) -> (311, 258): 3.0 pixels\n",
      "(311, 258) -> (312, 261): 3.1622776601683795 pixels\n",
      "(312, 261) -> (312, 260): 1.0 pixels\n",
      "(312, 260) -> (313, 261): 1.4142135623730951 pixels\n",
      "(313, 261) -> (311, 264): 3.605551275463989 pixels\n",
      "(311, 264) -> (316, 266): 5.385164807134504 pixels\n",
      "(316, 266) -> (308, 267): 8.06225774829855 pixels\n",
      "(308, 267) -> (310, 266): 2.23606797749979 pixels\n",
      "(310, 266) -> (311, 267): 1.4142135623730951 pixels\n",
      "(311, 267) -> (315, 271): 5.656854249492381 pixels\n",
      "(315, 271) -> (316, 270): 1.4142135623730951 pixels\n",
      "(316, 270) -> (315, 266): 4.123105625617661 pixels\n",
      "(315, 266) -> (318, 271): 5.830951894845301 pixels\n",
      "(318, 271) -> (318, 268): 3.0 pixels\n",
      "187.21474913886448 pixels\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for i, j in zip(center_of_grav_loc[:-1], center_of_grav_loc[1:]):\n",
    "    dist = ((j[0]-i[0])**2 + (j[1]-i[1])**2)**0.5\n",
    "    tot += dist\n",
    "    print(f\"{i} -> {j}: {dist} pixels\")\n",
    "print(tot, \"pixels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "centtr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
